#!/usr/bin/env python3

import os
import re
import requests
import json
from datetime import datetime

# é…ç½®å‚æ•°
RULE_SOURCES_FILE = 'sources.txt'          # è§„åˆ™æ¥æºæ–‡ä»¶
OUTPUT_FILE = 'merged-filter.txt'         # è¾“å‡ºæ–‡ä»¶
STATS_FILE = 'rule_stats.json'            # ç»Ÿè®¡æ–‡ä»¶
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
TITLE = "Merged Rules"                    # æ ‡é¢˜
VERSION = "1.0.0"                         # ç‰ˆæœ¬å·

# æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—åŒ–
REGEX_PATTERNS = {
    "comment": re.compile(r'^[!#]'),  # æ³¨é‡Šè¡Œ
    "blank": re.compile(r'^\s*$'),  # ç©ºè¡Œ
    "domain": re.compile(r'^(@@)?(\|\|)?([a-zA-Z0-9-*_.]+)(\^|\$|/)?'),
    "element": re.compile(r'##.+'),  # å…ƒç´ è§„åˆ™
    "regex_rule": re.compile(r'^/.*/$'),  # æ­£åˆ™è§„åˆ™
    "modifier": re.compile(r'\$(~?[\w-]+(=[^,\s]+)?(,~?[\w-]+(=[^,\s]+)?)*)$')
}

def is_valid_rule(line):
    """
    éªŒè¯è§„åˆ™æœ‰æ•ˆæ€§
    :param line: è§„åˆ™è¡Œ
    :return: æ˜¯å¦æœ‰æ•ˆ
    """
    if REGEX_PATTERNS["comment"].match(line) or REGEX_PATTERNS["blank"].match(line):
        return False
    return any([
        REGEX_PATTERNS["domain"].match(line),
        REGEX_PATTERNS["element"].search(line),
        REGEX_PATTERNS["regex_rule"].match(line),
        REGEX_PATTERNS["modifier"].search(line)
    ])

def download_rules(url):
    """
    ä¸‹è½½è§„åˆ™å¹¶éªŒè¯
    :param url: è§„åˆ™æ¥æº URL æˆ–æœ¬åœ°æ–‡ä»¶è·¯å¾„
    :return: (æœ‰æ•ˆè§„åˆ™åˆ—è¡¨, æ— æ•ˆè§„åˆ™åˆ—è¡¨)
    """
    valid_rules = []
    invalid_rules = []
    try:
        if url.startswith('file:'):
            # è¯»å–æœ¬åœ°æ–‡ä»¶
            file_path = url.split('file:')[1].strip()
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = [line.strip() for line in f]
        else:
            # ä¸‹è½½è¿œç¨‹æ–‡ä»¶
            resp = requests.get(url, headers={'User-Agent': USER_AGENT}, timeout=15)
            resp.raise_for_status()
            lines = [line.strip() for line in resp.text.splitlines()]

        for line in lines:
            if is_valid_rule(line):
                valid_rules.append(line)
            elif line and not (REGEX_PATTERNS["comment"].match(line) or REGEX_PATTERNS["blank"].match(line)):
                invalid_rules.append(line)

    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ ä¸‹è½½å¤±è´¥: {url} - {str(e)}")
    except FileNotFoundError:
        print(f"âš ï¸ æœ¬åœ°æ–‡ä»¶æœªæ‰¾åˆ°: {url}")
    except Exception as e:
        print(f"âš ï¸ æœªçŸ¥é”™è¯¯: {url} - {str(e)}")

    return valid_rules, invalid_rules

def write_stats(rule_count, total_count, title, version):
    """
    å†™å…¥è§„åˆ™ç»Ÿè®¡ä¿¡æ¯åˆ° JSON æ–‡ä»¶
    :param rule_count: æœ‰æ•ˆè§„åˆ™æ•°
    :param total_count: æ€»è§„åˆ™æ•°
    :param title: æ ‡é¢˜
    :param version: ç‰ˆæœ¬å·
    """
    stats = {
        "rule_count": rule_count,
        "total_count": total_count,
        "title": title,
        "version": version,
        "last_update": datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')
    }
    with open(STATS_FILE, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=4)
    print(f"âœ… å·²æ›´æ–°ç»Ÿè®¡ä¿¡æ¯: {STATS_FILE}")

def main():
    """
    ä¸»å‡½æ•°ï¼šå¤„ç†è§„åˆ™åˆå¹¶ã€éªŒè¯å’Œç»Ÿè®¡
    """
    print("ğŸ“‚ å¼€å§‹å¤„ç†è§„åˆ™æ–‡ä»¶")
    merged_rules = set()
    error_reports = {}

    # æ£€æŸ¥è§„åˆ™æ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(RULE_SOURCES_FILE):
        print(f"âŒ æœªæ‰¾åˆ°è§„åˆ™æ¥æºæ–‡ä»¶: {RULE_SOURCES_FILE}")
        return

    # è¯»å–è§„åˆ™æ¥æº
    with open(RULE_SOURCES_FILE, 'r', encoding='utf-8') as f:
        sources = [line.strip() for line in f if line.strip()]

    # ä¸‹è½½å¹¶éªŒè¯è§„åˆ™
    for url in sources:
        print(f"ğŸ“¥ æ­£åœ¨å¤„ç†: {url}")
        valid_rules, invalid_rules = download_rules(url)
        merged_rules.update(valid_rules)

        if invalid_rules:
            error_reports[url] = invalid_rules
            print(f"  âš ï¸ å‘ç° {len(invalid_rules)} æ¡æ— æ•ˆè§„åˆ™")

    # æ’åºè§„åˆ™
    sorted_rules = sorted(merged_rules, key=lambda x: (
        not x.startswith('||'),
        not x.startswith('##'),
        x
    ))

    # å†™å…¥åˆ°è¾“å‡ºæ–‡ä»¶
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write('\n'.join(sorted_rules))
        f.write(f"\n\n# Total count: {len(sorted_rules)}\n")
        f.write(f"# Title: {TITLE}\n")
        f.write(f"# Version: {VERSION}\n")
    print(f"âœ… è§„åˆ™åˆå¹¶å®Œæˆï¼Œè¾“å‡ºåˆ° {OUTPUT_FILE}")

    # å†™å…¥ç»Ÿè®¡ä¿¡æ¯
    write_stats(len(sorted_rules), len(sorted_rules), TITLE, VERSION)

    # è¾“å‡ºé”™è¯¯æŠ¥å‘Š
    if error_reports:
        print("\nâš ï¸ ä»¥ä¸‹æ¥æºå­˜åœ¨æ— æ•ˆè§„åˆ™:")
        for url, errors in error_reports.items():
            print(f"  - æ¥æº: {url}")
            for error in errors:
                print(f"    - æ— æ•ˆè§„åˆ™: {error}")

if __name__ == "__main__":
    main()